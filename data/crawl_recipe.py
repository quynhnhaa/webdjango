import time
import csv
import os
import requests
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import re
import random
import selenium.common.exceptions

# Bi·∫øn to√†n c·ª•c
recipe_ingredients = []
reviews = []
categories_recipe = []
users = []

def load_users(file_path):
    try:
        with open(file_path, mode="r", encoding="utf-8-sig") as f:
            reader = csv.DictReader(f)
            for row in reader:
                if row.get("username"):  
                    users.append(row)
        print(f"‚úÖ ƒê√£ load {len(users)} user t·ª´ {file_path}")
    except Exception as e:
        print(f"‚ùå L·ªói khi ƒë·ªçc user t·ª´ file {file_path}: {e}")
    return users

# Danh s√°ch ph√¢n lo·∫°i c√≥ s·∫µn
categories = {
    "Theo b·ªØa ƒÉn": [
        "B·ªØa s√°ng",
        "B·ªØa tr∆∞a",
        "B·ªØa t·ªëi",
        "B·ªØa x·∫ø",
        "ƒÇn khuya"
    ],
    "Theo v√πng mi·ªÅn/qu·ªëc gia": [
        "M√≥n Vi·ªát Nam",
        "M√≥n Trung Qu·ªëc",
        "M√≥n Nh·∫≠t B·∫£n",
        "M√≥n H√†n Qu·ªëc",
        "M√≥n √Çu",
        "M√≥n M·ªπ",
        "M√≥n ·∫§n ƒê·ªô",
        "M√≥n ƒê·ªãa Trung H·∫£i"
    ],
    "Theo ph∆∞∆°ng ph√°p ch·∫ø bi·∫øn": [
        "M√≥n lu·ªôc",
        "M√≥n h·∫•p",
        "M√≥n chi√™n",
        "M√≥n n∆∞·ªõng",
        "M√≥n x√†o",
        "M√≥n kho/rim",
        "M√≥n g·ªèi/salad",
        "M√≥n l·∫©u"
    ],
    "Theo ƒë·∫∑c ƒëi·ªÉm dinh d∆∞·ª°ng": [
        "M√≥n chay",
        "M√≥n gi√†u protein",
        "M√≥n √≠t carb/Keto",
        "M√≥n √≠t calo",
        "M√≥n gi√†u ch·∫•t x∆°"
    ],
    "Theo h√¨nh th·ª©c ƒÉn u·ªëng": [
        "M√≥n ƒÉn v·∫∑t",
        "M√≥n tr√°ng mi·ªáng",
        "M√≥n ƒÉn ƒë∆∞·ªùng ph·ªë",
        "M√≥n nh√† h√†ng",
        "M√≥n ƒÉn nhanh"
    ],
    "Theo d·ªãp ƒë·∫∑c bi·ªát": [
        "M√≥n ng√†y T·∫øt",
        "M√≥n Gi√°ng Sinh",
        "M√≥n ƒë√°m c∆∞·ªõi",
        "M√≥n sinh nh·∫≠t"
    ],
    "Theo ƒë·ªô kh√≥ n·∫•u": [
        "M√≥n ƒë∆°n gi·∫£n",
        "M√≥n trung b√¨nh",
        "M√≥n ph·ª©c t·∫°p"
    ]
}

# H√†m t√°ch nguy√™n li·ªáu v√† s·ªë l∆∞·ª£ng
def parse_ingredient(ingredient_text):
    """T√°ch nguy√™n li·ªáu v√† s·ªë l∆∞·ª£ng t·ª´ vƒÉn b·∫£n, ph√¢n t√°ch t·∫°i ch·ªØ s·ªë ƒë·∫ßu ti√™n ho·∫∑c d·∫•u hai ch·∫•m (n·∫øu tr∆∞·ªõc s·ªë), b·ªè qua 'ƒÇN K√àM', b·ªè d·∫•u hai ch·∫•m."""
    ingredient_text = ingredient_text.strip()
    
    if not ingredient_text or ingredient_text.startswith("ƒÇN K√àM"):
        return None
    
    # T√¨m ch·ªØ s·ªë ƒë·∫ßu ti√™n ho·∫∑c d·∫•u hai ch·∫•m
    number_pattern = r'\b\d'  
    colon_pattern = r':'
    
    # T√¨m v·ªã tr√≠ c·ªßa ch·ªØ s·ªë v√† d·∫•u hai ch·∫•m
    number_match = re.search(number_pattern, ingredient_text)
    colon_match = re.search(colon_pattern, ingredient_text)
    
    # X√°c ƒë·ªãnh ƒëi·ªÉm ph√¢n t√°ch (ch·ªØ s·ªë ho·∫∑c d·∫•u hai ch·∫•m, l·∫•y c√°i xu·∫•t hi·ªán ƒë·∫ßu ti√™n)
    split_pos = None
    if number_match and colon_match:
        split_pos = min(number_match.start(), colon_match.start())
    elif number_match:
        split_pos = number_match.start()
    elif colon_match:
        split_pos = colon_match.start()
    
    if split_pos is not None:
        ingredient = ingredient_text[:split_pos].strip()
        quantity = ingredient_text[split_pos:].strip()

        ingredient = ingredient.replace(":", "").strip()
        quantity = quantity.replace(":", "").strip()
    else:
        ingredient = ingredient_text.replace(":", "").strip()
        quantity = ""
    
    if not ingredient:
        return None
        
    return ingredient, quantity

# H√†m t·∫£i h√¨nh ·∫£nh
def download_image(driver, recipe_url, output_dir):
    """T·∫£i h√¨nh ·∫£nh t·ª´ URL c·ªßa c√¥ng th·ª©c v√† l∆∞u v√†o th∆∞ m·ª•c ch·ªâ ƒë·ªãnh."""
    try:
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "img.img_detail_monan"))
        )

        image_element = driver.find_element(By.CSS_SELECTOR, "img.img_detail_monan")
        image_url = image_element.get_attribute("src")
        image_name = image_element.get_attribute("alt").replace(" ", "_").replace("/", "_") + ".jpg"

        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        # T·∫£i h√¨nh ·∫£nh v√† l∆∞u v√†o t·ªáp
        response = requests.get(image_url)
        if response.status_code == 200:
            image_path = os.path.join(output_dir, image_name).replace("\\", "/")
            with open(image_path, "wb") as f:
                f.write(response.content)
            print(f"‚úÖ H√¨nh ·∫£nh ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {image_path}")
            return image_path
        else:
            print(f"‚ùå Kh√¥ng th·ªÉ t·∫£i h√¨nh ·∫£nh, m√£ ph·∫£n h·ªìi: {response.status_code}")
    except Exception as e:
        print(f"‚ùå L·ªói khi t·∫£i h√¨nh ·∫£nh t·ª´ {recipe_url}: {e}")
    
    return None

# L·∫•y t·∫•t c·∫£ c√°c b∆∞·ªõc S∆° Ch·∫ø, Th·ª±c Hi·ªán, v√† C√°ch D√πng v√† g·ªôp l·∫°i th√†nh m·ªôt instruction
def crawl_all_instructions(driver):
    """C√†o c√°c b∆∞·ªõc t·ª´ c√°c section S∆° Ch·∫ø, Th·ª±c Hi·ªán, C√°ch D√πng v·ªõi c·∫•u tr√∫c HTML kh√°c nhau."""
    try:
        instructions = []

        # S∆° Ch·∫ø: Ki·ªÉm tra c·∫£ <ul><li> v√† <div class="ewa-rteLine">
        soche_elements = []

        try:
            soche_elements = driver.find_elements(By.CSS_SELECTOR, "#section-soche ul li")
        except:
            pass

        try:
            soche_elements += driver.find_elements(By.CSS_SELECTOR, "#section-soche div.ewa-rteLine")
        except:
            pass

        if not soche_elements:
            try:
                soche_elements += driver.find_elements(By.CSS_SELECTOR, "#section-soche p")
            except:
                pass

        instructions.extend([element.text.strip() for element in soche_elements if element.text.strip().lstrip()])

        # Th·ª±c Hi·ªán: Ki·ªÉm tra c·∫£ <div><p> v√† <div class="ewa-rteLine">
        thuchien_elements = []
        try:
            thuchien_elements = driver.find_elements(By.CSS_SELECTOR, "#section-thuchien div p")
        except:
            pass
        try:
            thuchien_elements += driver.find_elements(By.CSS_SELECTOR, "#section-thuchien div.ewa-rteLine")
        except:
            pass
        if not thuchien_elements:
            try:
                thuchien_elements += driver.find_elements(By.CSS_SELECTOR, "#section-soche p")
            except:
                pass
        instructions.extend([element.text.strip() for element in thuchien_elements if element.text.strip().lstrip()])

        # C√°ch D√πng: Ki·ªÉm tra c·∫£ <div><p> v√† <div class="ewa-rteLine">
        cachdung_elements = []
        try:
            cachdung_elements = driver.find_elements(By.CSS_SELECTOR, "#section-howtouse div p")
        except:
            pass
        try:
            cachdung_elements += driver.find_elements(By.CSS_SELECTOR, "#section-howtouse div.ewa-rteLine")
        except:
            pass
        if not cachdung_elements:
            try:
                cachdung_elements += driver.find_elements(By.CSS_SELECTOR, "#section-soche p")
            except:
                pass
        instructions.extend([element.text.strip() for element in cachdung_elements if element.text.strip().lstrip()])

        # G·ªôp t·∫•t c·∫£ c√°c b∆∞·ªõc l·∫°i th√†nh m·ªôt chu·ªói
        return "\n".join(instructions) if instructions else None
    except Exception as e:
        print(f"‚ùå L·ªói khi c√†o c√°c b∆∞·ªõc: {e}")
        return None

# C√†o ph√¢n lo·∫°i t·ª´ c√¥ng th·ª©c
def crawl_categories(recipe_name, driver):
    try:
        WebDriverWait(driver, 10).until(
            EC.presence_of_all_elements_located((By.CSS_SELECTOR, "ul.tags > li > a"))
        )
        category_elements = driver.find_elements(By.CSS_SELECTOR, "ul.tags > li > a")
        crawled_categories = [element.text.strip() for element in category_elements]
        for group, valid_categories in categories.items():
            for crawled_category in crawled_categories:
                if crawled_category in valid_categories:
                    categories_recipe.append({
                        "recipe": recipe_name,
                        "category": crawled_category
                    })
    except Exception as e:
        print(f"‚ùå L·ªói khi c√†o ph√¢n lo·∫°i: {e}")

# C√†o chi ti·∫øt c√¥ng th·ª©c
def crawl_recipe_details(url, driver):
    try:
        driver.get(url)
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "h1 span.title"))
        )
    except Exception as e:
        print(f"‚ùå Kh√¥ng th·ªÉ load chi ti·∫øt t·ª´ {url}: {e}")
        return None

    try:
        name = driver.find_element(By.CSS_SELECTOR, "h1 span.title").text.strip()

        # H√¨nh ·∫£nh
        image_path = download_image(driver, url, "media/recipe_images").replace("media/", "")

        # M√¥ t·∫£
        description_elements = driver.find_elements(By.CSS_SELECTOR, ".detail_main > div > p")
        description = ""
        if description_elements:
            description_parts = []
            for element in description_elements:
                text = element.text.strip()
                if not text.startswith("Xem th√™m"):
                    description_parts.append(text)
            description = "\n".join(description_parts) if description_parts else ""

        # Th·ªùi gian n·∫•u
        cook_time = None
        try:
            cook_time_element = driver.find_element(By.XPATH, "//span[text()='Th·ªùi gian th·ª±c hi·ªán:']/following-sibling::strong")
            cook_time_text = cook_time_element.text.strip()
            cook_time = int(re.search(r'\d+', cook_time_text).group()) if cook_time_text else None
        except:
            pass

        # ƒê·ªô kh√≥
        level = "Kh√¥ng r√µ"
        try:
            level_element = driver.find_element(By.XPATH, "//span[text()='ƒê·ªô kh√≥:']/following-sibling::strong")
            level = level_element.text.strip()
        except:
            pass

        # C√†o nguy√™n li·ªáu
        ingredients_elements = driver.find_elements(By.CSS_SELECTOR, "#tab-muong ul li:not(.giavi)")
        for element in ingredients_elements:
            ingredient_text = element.text.strip()
            if ingredient_text:  # Ch·ªâ x·ª≠ l√Ω n·∫øu kh√¥ng r·ªóng
                parsed_ingredient = parse_ingredient(ingredient_text)
                if parsed_ingredient:  # Ch·ªâ th√™m n·∫øu kh√¥ng ph·∫£i "ƒÇN K√àM" ho·∫∑c kh√¥ng h·ª£p l·ªá
                    ingredient, quantity = parsed_ingredient
                    recipe_ingredients.append({
                        "recipe": name,
                        "ingredient": ingredient,
                        "quantity": quantity
                    })
                else:
                    print(f"‚ö†Ô∏è B·ªè qua nguy√™n li·ªáu kh√¥ng h·ª£p l·ªá: '{ingredient_text}'")

        # H∆∞·ªõng d·∫´n
        instructions = crawl_all_instructions(driver)

        # C√†o ph√¢n lo·∫°i
        crawl_categories(name, driver)

        # C√†o comment c·ªßa ng∆∞·ªùi xem 
        try:
            comment_elements = driver.find_elements(By.CSS_SELECTOR, ".list-all-comment > div")
            for comment in comment_elements:
                try:
                    username = comment.find_element(By.CSS_SELECTOR, "div > div > div > strong").text.strip()
                    if username != "M√≥n Ngon M·ªói Ng√†y":
                        comment_text = comment.find_element(By.CSS_SELECTOR, "p:not(.text-xs)").text.strip()
                        if comment_text:
                            reviews.append({
                                "recipe": name,
                                "user": random.choice(users),
                                "rating": random.randint(1, 5), 
                                "comment": comment_text
                            })
                except:
                    continue
        except:
            pass

        return {
            "name": name,
            "description": description,
            "cook_time": cook_time,
            "level": level,
            "instructions": instructions,
            "image_path": image_path
        }
    except Exception as e:
        print(f"‚ùå L·ªói khi c√†o d·ªØ li·ªáu t·ª´ {url}: {e}")
        return None

# C√†o danh s√°ch c√¥ng th·ª©c
def crawl_all_recipes(start_page_url, max_pages):
    """C√†o t·∫•t c·∫£ c√¥ng th·ª©c t·ª´ c√°c trang."""
    options = webdriver.ChromeOptions()
    options.headless = False
    driver = webdriver.Chrome(options=options)

    all_recipes = []
    page = 1

    try:
        while page <= max_pages:
            page_url = f"{start_page_url}/page/{page}/"
            print(f"üîÑ ƒêang c√†o trang {page}: {page_url}")
            driver.get(page_url)

            try:
                WebDriverWait(driver, 10).until(
                    EC.presence_of_all_elements_located((By.CSS_SELECTOR, "h3.font-bold > a"))
                )
            except:
                print("‚ùå Kh√¥ng c√≥ th√™m link n√†o, d·ª´ng l·∫°i.")
                break

            try:
                link_elements = driver.find_elements(By.CSS_SELECTOR, "h3.font-bold > a")
                recipe_urls = [el.get_attribute("href") for el in link_elements if el.get_attribute("href")]

                if not recipe_urls:
                    print("‚ùå Kh√¥ng t√¨m th·∫•y link n√†o.")
                    break

                for recipe_url in recipe_urls:
                    try:
                        print(f"‚û°Ô∏è C√†o d·ªØ li·ªáu t·ª´: {recipe_url}")
                        recipe_data = crawl_recipe_details(recipe_url, driver)
                        if recipe_data:
                            all_recipes.append(recipe_data)
                    except selenium.common.exceptions.StaleElementReferenceException:
                        print("‚ö†Ô∏è L·ªói StaleElementReferenceException: B·ªè qua li√™n k·∫øt ƒë√£ stale.")
                        continue
                    except Exception as e:
                        print(f"‚ùå L·ªói kh√°c khi x·ª≠ l√Ω li√™n k·∫øt {recipe_url}: {e}")
                        continue

            except selenium.common.exceptions.StaleElementReferenceException:
                print("‚ö†Ô∏è L·ªói StaleElementReferenceException khi l·∫•y danh s√°ch li√™n k·∫øt, th·ª≠ l·∫°i trang.")
                continue

            page += 1
            time.sleep(random.uniform(1, 3)) 
    finally:
        driver.quit()

    return all_recipes


# L∆∞u d·ªØ li·ªáu v√†o CSV
def save_to_csv(data, filename, fieldnames):
    with open(filename, mode="w", encoding="utf-8-sig", newline="") as file:
        writer = csv.DictWriter(file, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(data)
    print(f"‚úÖ ƒê√£ l∆∞u d·ªØ li·ªáu v√†o: {filename}")

# Main
if __name__ == "__main__":
    users = load_users("data/users.csv")
    
    start_url = "https://monngonmoingay.com/tim-kiem-mon-ngon"
    recipes = crawl_all_recipes(start_url, max_pages=198)

    save_to_csv(recipes, "data/recipes.csv", ["name", "description", "cook_time", "level", "instructions", "image_path"])
    save_to_csv(recipe_ingredients, "data/recipe_ingredients.csv", ["recipe", "ingredient", "quantity"])
    save_to_csv(reviews, "data/reviews.csv", ["recipe", "user", "rating", "comment"])
    save_to_csv(categories_recipe, "data/categories_recipe.csv", ["recipe", "category"])

    # L∆∞u danh s√°ch nguy√™n li·ªáu v√†o ingredients.csv
    unique_ingredients = [{"ingredient": item} for item in sorted({ri["ingredient"] for ri in recipe_ingredients})]
    save_to_csv(unique_ingredients, "data/ingredients.csv", ["ingredient"])

    print("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c l∆∞u th√†nh c√¥ng!")